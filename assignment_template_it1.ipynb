{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a716389a-e46c-4e15-b473-b40d7c79a1d3",
   "metadata": {},
   "source": [
    "##### Instructions\n",
    "- Keep the original structure, you may add additional code cells and/or mark-down cells for clarity, legibility and/or structure.\n",
    "- Add the required descriptions, explanations, justifications to the mark-down cells. You can find more mark-down tips & tricks online, for example [here](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html) and [here](https://www.ibm.com/docs/en/watson-studio-local/1.2.3?topic=notebooks-markdown-jupyter-cheatsheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b017957-b9de-4e04-8dad-d90e9bea213d",
   "metadata": {},
   "source": [
    "# EXAM03: Data Science Group Assignment - Iteration 1\n",
    "\n",
    "**Group name:** Docker commit down -m --build\n",
    "\n",
    "**Student names & numbers:**\n",
    "* Iulia Bacanu - 099559\n",
    "* Shaiza Khatoon - 00099918\n",
    "* Lars Loois - 101333\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e735319e-ed1e-45a0-a976-2aff38fd4180",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 0. Iteration setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c92ec16",
   "metadata": {},
   "source": [
    "Before importing anything in the File. The first step is to create a virtual enviroment via terminal. The following must be installed in order for the entire assignment to work properly (Excluing hashes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490e317f",
   "metadata": {},
   "source": [
    "## On Window's Powershell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f299ef01",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "python3 -m venv venv # Create the virtual enviroment\n",
    ".\\venv\\Scripts\\Activate.ps1 # enter into the enviroment\n",
    "pip install pandas # installing pandas\n",
    "pip install scikit-learn # installing scikit\n",
    "\n",
    "# Install the rest of the libraries by using pip install [library name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b85c7",
   "metadata": {},
   "source": [
    "## On MacOS/Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7e62e6",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "python3 -m venv venv # Create the virtual enviroment\n",
    "source venv/bin/activate # enter into the enviroment\n",
    "pip install pandas # installing \n",
    "pip install scikit-learn # installing scikit\n",
    "\n",
    "# Install the rest of the libraries by using pip install [library name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79f6f7d-068b-4554-8d4e-c088a8909db4",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc780e8c-cba7-450e-b5d5-6b2445a11681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL: import the necessary libraries for this iteration\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4cb004-acbc-4566-abd1-fc4d5345d47d",
   "metadata": {},
   "source": [
    "**Load dataset(s)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cffc45c-3fdb-4e7c-9e6a-cb6983a5d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL: import the necessary dataset(s) for this iteration\n",
    "\n",
    "df = pd.read_csv('Data/ships_inventory_iter1.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea875bf-f228-4c0f-b353-206a163ec75c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Business Understanding\n",
    "*Rubric: LO 6.4D (Reflection on Process)*\n",
    "\n",
    "**Situation description**\n",
    "\n",
    "*Describe the Nebula Brokerage pricing problem. Why is their current \"gut feeling\" approach a risk?.*\n",
    "\n",
    "*Nebula Brokerage lacks a standardized pricing model. A sector or company would price a ship higher or lower than intended resulting to some a revenue leakage, meaning that they would become underpriced or over priced causing a loss of profit and respectfully a longer selling time.\n",
    "\n",
    "This specific problem can lead the company to be inconsisntant by managing the other sectors and ships, and can lead to banckrupcy in the near future.*\n",
    "\n",
    "**Business objective(s)**\n",
    "\n",
    "*Justify why a data-driven baseline is needed*\n",
    "\n",
    "*By using a data-driven baseline to determain the pricings. It will help the company know and identify weather a model has been priced fairly or unfair, making sure that the models stay consistant with the pricing regardless of the sector.*\n",
    "\n",
    "**Data mining goal(s)**\n",
    "\n",
    "*Explain what type of modeling task this is and why.*\n",
    "\n",
    "This is a regression modeling task because the objective is to predict a numerical value, which is the shipâ€™s price (Galactic_Credits). Since price is a continuous variable that can take many possible values, the problem is not classification (which predicts categories), but regression.\n",
    "\n",
    "The goal at this stage is to determine a baseline price that minimizes the average prediction error across all ships. Therefore, we are working with a quantitative prediction problem, making this a regression task.\n",
    "\n",
    "**Success criteria**\n",
    "\n",
    "*Determine success criteria for this iteration (the benchmark)*\n",
    "THe success criteria would be when the system can give the company a good price where customers are satisfied with, the dealer don't have to wait ages to sell a ship and doesn't have a revenue leakage.\n",
    "\n",
    "By this means the system needs an algorith that will base the price on all availible data in de .csv and need to work by specific rules that are set up by the company\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd5f790-54b1-4ee4-838f-2e813e3513be",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data Understanding\n",
    "*Rubric: LO 7.3Q (Visuals) & LO 6.4C (Process)*\n",
    "\n",
    "**Data exploration**\n",
    "\n",
    "*Include summary statistics and descriptions of data types below. Describe your findings.*\n",
    "\n",
    "* Ship_ID = ID number of the ship, integer\n",
    "* Galactic_Credits = The cost of the ship by galactic credits, integer\n",
    "* Model_Cycle = the type of model of the ships, more specifically the year of the ship that has been created, float\n",
    "* Ship_Manufacturer = The company that manufactured the ship, string\n",
    "* Sector = the location of the ship and where it's being sold, string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f5251d-5aee-4b9f-8564-193785930d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL: Show basic statistics and information\n",
    "df.info() # Reciving information about the dataframe provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96797443-654e-4a65-a9fa-84a8a3fbf741",
   "metadata": {},
   "source": [
    "**Visualizations and patterns**\n",
    "\n",
    "*Discover patterns in the data by creating visualizations. Create at least a histogram of Galactic_Credits. Describe your observations.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb4c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['Galactic_Credits'], bins=50)\n",
    "plt.title('Distribution of Galactic Credits')\n",
    "plt.xlabel('Galactic Credits')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Model_Cycle'], df['Galactic_Credits'])\n",
    "plt.xlabel('Model Cycle')\n",
    "plt.ylabel('Galactic Credits')\n",
    "plt.title('Price vs Model Cycle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65918398-cc3a-4986-8530-8e32b69681cc",
   "metadata": {},
   "source": [
    "**Data insights and data quality**\n",
    "* **Insights:** What are the key trends? What does the distribution look like? What does that mean? \n",
    "* **Quality issues:** Document missing values, duplicates, outliers, etc.\n",
    "\n",
    "* **Insights:**\n",
    "\n",
    "* **Quality issues:** \n",
    "- some ships provided lack a model cycle and they are not provided.\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f69990a-91c8-48ff-bf04-8658c6e2e6a6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Data Preparation\n",
    "*Rubric: LO 6.4C (Data Science Steps)*\n",
    "\n",
    "**Cleaning and preprocessing**\n",
    "*Describe and justify steps taken (e.g., imputation, handling outliers, fixing other errors).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f186c7a-10d1-4808-9818-e14ab7d116b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL: Data cleaning and preprocessing steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9974d45f-a56b-4a13-b8e9-daf8ef5029bf",
   "metadata": {},
   "source": [
    "**Adjusting dataset (optional)**\n",
    "*If you adjusted the dataset for modeling in additional ways, describe that here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9b7120d-8bad-4b78-84bf-d62c7d503aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL CODE CELL: Additional preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91a9873-64fa-4b76-b891-8ffd2e968728",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Modeling\n",
    "*Rubric: LO 6.4C (Data Science Steps)*\n",
    "\n",
    "**Model setup**\n",
    "*Describe and justify the creation of your simple benchmark model to predict Galactic_Credits*\n",
    "\n",
    "**Describtion:**\n",
    "A simple benchmark model has been created to predict the values of Galactic_Credits.\\\n",
    "\n",
    "The benchmark model will predict the mean values of Galactic_Credits for all the data points.\n",
    "\n",
    "The simple model will be used as a basis to compare the advanced predictive model.\n",
    "\n",
    "The performance of the model has been evaluated using the Mean Absolute Error (MAE).\n",
    "\n",
    "Benchmark MAE: 11607.02\n",
    "\n",
    "The advanced predictive model will not add any predictive value if it does not perform better than this simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd902930-dbad-4e7a-854b-2b6a31774d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL: Model training and setup code\n",
    "if \"Galactic_Credits\" not in df.columns:\n",
    "    raise ValueError(\"Can't find column 'Galactic_Credits' in the .CSV.\")\n",
    "\n",
    "mean_credits = df[\"Galactic_Credits\"].mean()\n",
    "\n",
    "df[\"Benchmark_Prediction\"] = mean_credits\n",
    "\n",
    "mae = abs(df[\"Galactic_Credits\"] - df[\"Benchmark_Prediction\"]).mean()\n",
    "\n",
    "print(\"Average Galactic Credits:\", round(mean_credits, 2))\n",
    "print(\"Benchmark MAE:\", round(mae, 2))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(df.index, df[\"Galactic_Credits\"])\n",
    "\n",
    "plt.plot(df.index, df[\"Benchmark_Prediction\"])\n",
    "\n",
    "plt.title(\"Benchmark Model vs Actual Galactic Credits\")\n",
    "plt.xlabel(\"Data Index\")\n",
    "plt.ylabel(\"Galactic Credits\")\n",
    "plt.legend([\"Benchmark Prediction\", \"Actual Values\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e31d2ad-37e3-462e-87c0-feed5d13b6a7",
   "metadata": {},
   "source": [
    "**Testing and performance**\n",
    "*Describe how you tested the model and interpret the metrics. Make sure to present the metrics in a clear overview.*\n",
    "\n",
    "**Describtion**\n",
    "To assess the benchmark model, the data was divided into a training dataset (80%) and a test dataset (20%).\n",
    "The average value of *Galactic_Credits* in the training dataset was set as a fixed prediction for every data point in the test dataset.\n",
    "\n",
    "The performance of the model was assessed using three different metrics:\n",
    "\n",
    "- **Mean Absolute Error (MAE)**\n",
    "- **Mean Squared Error (MSE)**\n",
    "- **Root Mean Squared Error (RMSE)**\n",
    "\n",
    "### Performance Results\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|--------|\n",
    "| MAE | 11,639 |\n",
    "| MSE | 253,859,769 |\n",
    "| RMSE | 15,932 |\n",
    "\n",
    "The MAE shows that the average prediction error of the model is 11,639 Galactic Credits.  \n",
    "The RMSE is higher than the MAE, which shows the presence of large prediction errors (outliers) in the data, as RMSE gives more weight to large errors.\n",
    "\n",
    "These results show that the benchmark model has a high prediction error. Hence, the benchmark model becomes a baseline that needs to be beaten by more sophisticated models in order to offer any useful predictive gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc70ff-ca1d-4cfd-b9ef-e65c86a7a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL: Model evaluation \n",
    "y = df[\"Galactic_Credits\"]\n",
    "\n",
    "y_train, y_test = train_test_split(y, test_size=0.2, random_state=42)\n",
    "\n",
    "mean_train = y_train.mean()\n",
    "\n",
    "y_pred = np.full(len(y_test), mean_train)\n",
    "\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "mse = np.mean((y_test - y_pred) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Benchmark Performance:\")\n",
    "print(\"MAE:\", round(mae, 2))\n",
    "print(\"MSE:\", round(mse, 2))\n",
    "print(\"RMSE:\", round(rmse, 2))\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Metric\": [\"MAE\", \"MSE\", \"RMSE\"],\n",
    "    \"Value\": [mae, mse, rmse]\n",
    "})\n",
    "\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1b7202-d834-4571-8ce0-b7c8944058fe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Evaluation\n",
    "*Rubric: LO 6.4C (Results vs. Objectives)*\n",
    "\n",
    "**Assessment against succes criteria** \n",
    "*What is the difference between the metrics? What does this mean? Did you meet the goals set in the Business Understanding?*\n",
    "\n",
    "**Key findings and limitations**\n",
    "*What did you learn? What are the limitations of this current model?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5f4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f79c53c2-ca1c-4182-ab8a-1bc1ba693eaf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6 Personal Contribution\n",
    "*Rubric: LO 7.3P (Equal Contribution)*\n",
    "\n",
    "| Student name | Contribution | Personal lessons learned |\n",
    "| :--- | :--- | :--- |\n",
    "| Iulia Bacanu | *Implemented the iteration setup; describing the initial situation; identifying the type of data, creating visualizations* | *How to properly set up an enviroment, importing, and loading files in order to have a working assignment and helping classmates by understanding how to create enviroments; give a bref description of the major problem; diffirentiate the types of data; created the visualizations by imprting the necceserry diagrams * |\n",
    "| Shaiza Khatoon | *Contribution description* | *Personal lessons learned this iteration* |\n",
    "| Lars Loois | did part 4 | Learned how to create diagrams and how to test and see how it performances in the case it's  needed  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb13c29",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
